# CS1 条件B: Paper Format — RAG引用リナンバリング (Run 3)

> **Run**: CS1-B-Run3
> **Date**: 2026-02-22
> **Model**: Claude Sonnet 4.6
> **Context**: Fresh agent invocation

---

# ストリーミングRAGシステムにおける引用番号の逐次確定問題：設計パターンの分析

## 概要

Retrieval-Augmented Generation（RAG）システムにおいて、大規模言語モデル（LLM）がストリーミング方式で回答を生成する場合、引用番号のリアルタイム表示と最終的な整合性の確保は技術的に難しい問題である。本稿では、この問題を形式化し、三つの主要設計パターンを分析する。各パターンはトレードオフが異なり、ユースケースに応じた選択が必要である。また、各パターンの実装上の留意点と、実用的な推奨構成についても論じる。

**キーワード**: RAG, ストリーミング生成, 引用番号, 逐次確定, UX設計

---

## 1. 問題の定義

### 1.1 背景

RAGシステムの典型的なアーキテクチャでは、ユーザーのクエリに対してベクトルデータベース等から関連文書を検索し、その結果をコンテキストとしてLLMに提供する。LLMはこれらの検索結果を参照しながら回答を生成するが、内部的には `source_3` や `source_7` のような識別子で参照する。

一方、エンドユーザーへの表示においては、`[1]`、`[2]`、`[3]` のような連番形式が可読性の観点から望ましい。しかしストリーミング生成では、回答全文が確定する前から部分的なテキストをユーザーに表示するため、以下の問題が発生する。

### 1.2 問題の形式化

設計が満たすべき三つの制約を定義する。

**制約C1（リアルタイム表示）**: 引用番号は、その引用が本文中に初めて登場した時点で即座に表示されなければならない。ユーザーはストリーミング完了を待たずに引用番号を確認できる必要がある。

**制約C2（番号不変性）**: 一度ユーザーに表示された引用番号は、その後変更されてはならない。番号の変更はユーザーの認知的負荷を高め、信頼性を損なう。

**制約C3（終端整合性）**: ストリーム完了時点で、本文中の引用番号とソース一覧の番号が完全に一致しなければならない。孤立した引用番号や、本文中で参照されないソースが一覧に存在してはならない。

この三制約を同時に満たすことが本稿の設計目標である。

### 1.3 問題の本質的な困難

問題の困難さは「割り当てタイミングの非対称性」にある。

ユーザーへの表示は**逐次的**（テキストが流れるたびに更新）であるが、引用番号の最終的な割り当てには**全域的**な情報（「この回答において合計何個の引用が使われるか、どの順番で登場するか」）が必要である。

ストリーミング完了前には全域的な情報が存在しないため、制約C1（リアルタイム）と制約C2・C3（整合性）の間には本質的な張力がある。

---

## 2. 関連研究・先行技術

### 2.1 遅延レンダリングアプローチ

最も単純な解決策は、ストリーミング完了後に引用番号を割り当てるものである。この手法はC2・C3を保証するが、C1を犠牲にする。多くの初期RAGシステム（例：初期のPerplexity AI実装）がこの戦略を採用していたと報告されている。

### 2.2 プレースホルダー方式

Menick et al.（2022）の WebGPT における引用機構は、モデルが明示的な引用マーカーを出力し、後処理で置換する設計を取る。この設計思想は本稿のPattern 2の基礎となっている。

### 2.3 段階的コミット

データベースシステムにおける楽観的ロック（optimistic locking）の概念を応用し、仮割り当てを行った上で後から確定する手法がストリーミングUIにも応用できる。

---

## 3. 設計パターンの分析

### 3.1 Pattern A: 先着順即時割り当て（First-Come First-Assigned）

#### 概要

本文中に引用が初めて登場した順番に従って、即座に連番を割り当てる方式である。

```
登場順序: source_3 → source_7 → source_3（再登場） → source_1
割り当て:  [1]       [2]         [1]（変化なし）      [3]
```

#### アルゴリズム

```
allocation_map = {}  # source_id -> display_number
counter = 1

on_token(token):
    if token contains citation_marker:
        source_id = extract_source_id(token)
        if source_id not in allocation_map:
            allocation_map[source_id] = counter
            counter += 1
        display_number = allocation_map[source_id]
        emit "[{display_number}]"
    else:
        emit token

on_stream_complete():
    emit_source_list(allocation_map)
```

#### 制約の充足

| 制約 | 充足状況 | 説明 |
|------|----------|------|
| C1 リアルタイム表示 | 完全充足 | 登場と同時に番号を割り当て・表示 |
| C2 番号不変性 | 完全充足 | 一度割り当てた番号は変更しない |
| C3 終端整合性 | 完全充足 | ストリーム完了時、使用されたソースのみ一覧に掲載 |

#### 評価

Pattern Aは三制約すべてを充足する。実装が単純であり、メモリ消費も `allocation_map` の大きさ（通常は数件〜十数件）に限られる。

ただし、番号の意味的秩序が失われる点に留意が必要である。ユーザーが事前に「最も重要なソースが[1]である」と期待する場合、その期待は裏切られる。番号は単に登場順を示すものとなる。これは制約違反ではなく設計上の特性であり、UIレベルでの説明が推奨される。

また、LLMが同一ソースを異なる識別子で参照する場合（例：`source_3` と `doc_3` が同一文書を指す）には、重複排除のための正規化処理が前処理段階で必要となる。

### 3.2 Pattern B: プレースホルダー置換（Placeholder Substitution）

#### 概要

ストリーミング中は引用番号の代わりにプレースホルダーを表示し、ストリーム完了後に正式な番号で置換する方式である。

```
ストリーミング中: "この研究[?]によれば..."
完了後の置換:    "この研究[1]によれば..."
```

#### アルゴリズム

```
placeholder_sequence = 0

# ストリーミング中
on_citation_encountered(source_id):
    placeholder_id = "?" + str(placeholder_sequence)
    placeholder_sequence += 1
    record_placeholder(placeholder_id, source_id)
    emit "[{placeholder_id}]"

# ストリーム完了後
on_stream_complete():
    final_allocation = compute_final_allocation()  # 任意の順序で計算可能
    for each placeholder in recorded_placeholders:
        replace_in_display(placeholder.id, final_allocation[placeholder.source_id])
    emit_source_list(final_allocation)
```

#### 制約の充足

| 制約 | 充足状況 | 説明 |
|------|----------|------|
| C1 リアルタイム表示 | 部分充足 | 引用の存在はリアルタイムに表示されるが、番号は未確定 |
| C2 番号不変性 | 完全充足 | 正式な番号は一度だけ確定される |
| C3 終端整合性 | 完全充足 | 最終割り当て時に整合性を保証できる |

#### 評価

Pattern Bは番号の意味的秩序を維持できる利点を持つ。たとえば、頻出順や検索スコア順での番号割り当てが可能である。

一方、C1の充足が「部分的」である点が重要な制限となる。プレースホルダー（`[?]`など）はユーザーに対して「引用があること」は伝えるが、具体的な番号は提供しない。これが許容されるかはUX要件次第である。

技術的な実装上の課題として、プレースホルダーの置換は表示済みテキストの遡及的更新を必要とする。Webフロントエンドにおいては、仮想DOMの差分更新やWebSocketを通じたパッチ送信によって実現できるが、実装複雑度は Pattern A より高い。

ストリームが途中で中断した場合、プレースホルダーが残存する可能性があるため、タイムアウトと fallback 処理が必要である。

### 3.3 Pattern C: 二段階ストリーミング（Two-Phase Streaming）

#### 概要

ストリーミングを二つのフェーズに分割する。第一フェーズでLLMに引用計画（どのソースを使うか）を生成させ、第二フェーズで本文を生成する。

```
Phase 1（高速）: {"citations": ["source_3", "source_7", "source_1"]}
→ 番号割り当て: source_3=[1], source_7=[2], source_1=[3]
Phase 2（本文）: ストリーミング開始、確定済み番号を使用
```

#### アルゴリズム

```
# Phase 1: 引用計画の生成
prompt_phase1 = build_citation_plan_prompt(query, retrieved_sources)
citation_plan = llm.generate_json(prompt_phase1)  # 非ストリーミング
allocation_map = assign_numbers(citation_plan.citations)

# Phase 2: 本文のストリーミング生成
prompt_phase2 = build_response_prompt(query, retrieved_sources, allocation_map)
for token in llm.stream(prompt_phase2):
    emit token
emit_source_list(allocation_map)
```

#### 制約の充足

| 制約 | 充足状況 | 説明 |
|------|----------|------|
| C1 リアルタイム表示 | 完全充足 | Phase 2では確定済み番号でリアルタイム表示 |
| C2 番号不変性 | 完全充足 | Phase 1で番号が確定してからPhase 2開始 |
| C3 終端整合性 | 条件付き充足 | Phase 2がPhase 1の計画に従う場合に限り保証 |

#### 評価

Pattern Cは番号を完全に事前確定できる設計上の優雅さを持つ。Phase 2のストリーミングでは「変更されない番号」を使用するため、フロントエンドの実装も Pattern A と同様に単純化できる。

しかしながら、この方式には複数の重大な問題がある。

第一に、**レイテンシの増加**。Phase 1の完了を待ってからPhase 2を開始するため、ユーザーが最初のテキストを見るまでの時間（Time-to-First-Token）が延長される。体感的なレスポンス速度が低下し、RAGのストリーミング採用動機と相反する。

第二に、**Phase 2がPhase 1の計画を逸脱するリスク**。LLMは決定論的ではないため、Phase 2の本文生成において Phase 1で計画されていないソースを参照する可能性がある。これはC3の違反につながる。対策として、Phase 2のプロンプトで厳密な制約を設けることができるが、完全な保証は困難である。

第三に、**LLM呼び出しコストの増加**。二回のLLM呼び出しが必要となり、コストとレイテンシの両面で負担が増す。

---

## 4. パターン比較と選択指針

### 4.1 総合比較

| 評価軸 | Pattern A | Pattern B | Pattern C |
|--------|-----------|-----------|-----------|
| C1 リアルタイム表示 | 完全充足 | 部分充足 | 完全充足 |
| C2 番号不変性 | 完全充足 | 完全充足 | 完全充足 |
| C3 終端整合性 | 完全充足 | 完全充足 | 条件付き充足 |
| 実装複雑度 | 低 | 中 | 高 |
| レイテンシ影響 | なし | なし | 増加 |
| 番号の意味的秩序 | 非保証 | 保証可能 | 保証可能 |
| ストリーム中断への耐性 | 高 | 中 | 低 |

### 4.2 選択指針

**Pattern Aを推奨する場合**: 実装の単純性を優先する場合、番号の意味的秩序が不要な場合（例：引用番号は単なるアンカーとして機能し、順序に意味がない場合）、高信頼性（ストリーム中断への耐性）が必要な場合。

**Pattern Bを推奨する場合**: 番号の意味的秩序が重要な場合（例：引用の重要度順に番号を割り当てたい場合）、フロントエンドが動的な差分更新に対応している場合、ストリーム完了後のわずかな遅延が許容される場合。

**Pattern Cを推奨する場合**: バッチ処理や非対話型のユースケース（リアルタイム性が不要な場合）、引用の意味的秩序が非常に重要で、かつレイテンシの増加が許容される場合。一般的な対話型RAGには推奨しない。

---

## 5. 実装上の共通考慮事項

### 5.1 引用マーカーの検出

LLMが出力する引用マーカー（`source_3` 等）の形式は、プロンプト設計によって制御する必要がある。曖昧な形式では、正規表現やパーサーによる確実な検出が困難となる。

推奨されるシステムプロンプトの指示例：

```
引用を示す場合は、必ず [[SOURCE:source_id]] の形式を使用してください。
例: [[SOURCE:source_3]]
この形式以外での引用表記は行わないでください。
```

明確なデリミタを設定することで、ストリーミングトークン列からの引用マーカー検出が確実になる。

### 5.2 部分トークンへの対応

ストリーミングでは、引用マーカーが複数のトークンに分割されて送信される場合がある（例：`[[SOURCE` / `:source_3` / `]]`）。この場合、バッファリング機構が必要である。

```
buffer = ""

on_token(token):
    buffer += token
    while True:
        if complete_marker in buffer:
            process_complete_marker(buffer)
            buffer = buffer_after_marker
        elif buffer_is_potential_marker_prefix(buffer):
            break  # 次のトークンを待つ
        else:
            emit buffer
            buffer = ""
```

### 5.3 エラーハンドリングとフォールバック

ネットワーク切断等によるストリームの中断に備え、以下のフォールバック戦略を設ける。

- **Pattern A・B共通**: 中断時点での `allocation_map` を用いてソース一覧を表示する（既表示の引用番号との整合性は維持される）。
- **Pattern B固有**: 未置換のプレースホルダーが残存する場合、タイムアウト後に `[参照不明]` 等の表示に変換する。

---

## 6. 推奨構成

本稿の分析に基づき、一般的な対話型RAGシステムに対しては **Pattern A（先着順即時割り当て）** を基本推奨とする。

根拠は以下の通りである。

1. **三制約の完全充足**: C1・C2・C3をすべて満たす唯一のパターンである（Pattern Cは条件付き）。
2. **実装の単純性**: バグが混入しにくく、保守性が高い。
3. **レイテンシへの無影響**: ユーザー体験の主要指標であるTime-to-First-Tokenに影響しない。
4. **高い耐障害性**: ストリームが中断した場合でも、表示済みの引用番号は整合した状態を保つ。

番号の意味的秩序が強く要求される場合（例：検索スコア上位のソースを[1]とする設計方針が明確に定められている場合）には、Pattern Bを選択し、フロントエンドの差分更新実装コストを受け入れることを推奨する。

---

## 7. 結論

本稿では、RAGストリーミングシステムにおける引用番号のリアルタイム表示と整合性確保の問題を、三制約（C1リアルタイム表示、C2番号不変性、C3終端整合性）として形式化した。そして三つの設計パターン（先着順即時割り当て、プレースホルダー置換、二段階ストリーミング）を設計・実装・耐障害性の観点から分析した。

分析の結果、Pattern A（先着順即時割り当て）が三制約をすべて充足しつつ、実装複雑度とレイテンシの点で最も優れた選択肢であることを示した。番号の意味的秩序を要求する場合にはPattern Bが代替となるが、フロントエンドの実装複雑度の増加を伴う。Pattern Cは対話型ユースケースには一般に不適切である。

今後の課題として、LLMが計画外の引用を自発的に追加・削除する動的な引用変動への対応、および複数のRAGエージェントが並列動作する分散環境における引用識別子の衝突管理が挙げられる。

---

## 参考文献

[1] Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. *Advances in Neural Information Processing Systems*, 33, 9459–9474.

[2] Menick, J., et al. (2022). Teaching Language Models to Support Answers with Verified Quotes. *arXiv preprint arXiv:2203.11147*.

[3] Shi, F., et al. (2023). Large Language Models Can Be Easily Distracted by Irrelevant Context. *Proceedings of ICML 2023*.

[4] Izacard, G., & Grave, E. (2021). Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering. *Proceedings of EACL 2021*, 874–880.

[5] Gao, Y., et al. (2023). Retrieval-Augmented Generation for Large Language Models: A Survey. *arXiv preprint arXiv:2312.10997*.
