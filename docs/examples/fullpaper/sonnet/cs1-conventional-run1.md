# CS1 条件A: Conventional — RAG引用リナンバリング (Run 1)

> **Run**: CS1-A-Run1
> **Date**: 2026-02-22
> **Model**: Claude Sonnet 4.6
> **Context**: Fresh agent invocation

---

# RAGシステムにおけるストリーミング引用リナンバリング設計分析

## 問題の本質

この問題の核心は「番号の確定性」と「ストリーミングのリアルタイム性」の矛盾にある。

通常のRAGパイプラインでは、LLMが内部的に `source_3`、`source_7` のような検索エンジン由来の識別子を使って回答を生成する。ユーザーに提示する `[1]`、`[2]` という番号は、その内部識別子とは独立した表示用の連番である。問題は、ストリーミング中に `[1]` を表示した時点では、その後のテキストに新たな引用が出現するかどうかわからない点だ。

## アーキテクチャ選択肢の分析

### 選択肢1: ポストプロセッシング方式（バッファリング）

ストリーム全体をサーバー側でバッファし、完全なテキストが確定してから変換・送信する。

**動作原理:**
1. LLMからのストリームをすべてサーバーメモリに蓄積する
2. ストリーム完了後、`source_3` → `[1]`、`source_7` → `[2]` のようにリナンバリングする
3. 変換済みテキストを一括または再ストリームしてクライアントへ送信する

**利点:**
- 番号の整合性が完全に保証される
- 実装がシンプルで理解しやすい
- 引用の最終的な出現順序で綺麗な連番が振れる

**欠点:**
- ストリーミングの体験を完全に損なう。ユーザーはLLMの応答完了まで何も見えない
- LLMの応答が長い場合、待機時間が顕著になる
- ストリーミングを売りにしたUIには使えない

この方式はストリーミングの利点を放棄するため、要件を満たさない。

---

### 選択肢2: ファーストアピアランス方式（到着順採番）

引用が初めてストリームに出現した瞬間に番号を割り当てる。

**動作原理:**
1. LLMからのトークンストリームをリアルタイムで監視する
2. 内部識別子（`source_3` など）が初めて出現した時点で、次の連番を割り当てる
3. 以降、同じ識別子が出現した場合は同じ番号を使う
4. マッピングテーブル `{ source_3: 1, source_7: 2, ... }` を維持する

**動作例:**
```
LLMストリーム: "この手法は[source_3]で提案され、後に[source_7]で改良されました。
               [source_3]の実験では..."

変換後出力:    "この手法は[1]で提案され、後に[2]で改良されました。
               [1]の実験では..."

最終的なソース一覧:
  [1] source_3 の内容
  [2] source_7 の内容
```

**利点:**
- リアルタイムストリーミングが維持される
- 一度割り当てた番号は変わらない（要件を満たす）
- ストリーム完了時のソース一覧と完全に整合する
- 実装が現実的なコストで可能

**欠点:**
- 番号は「文章中の初出順」に基づく。検索結果の関連度順や重要度順にはならない
- LLMが内部識別子を途中で切り詰めたり変形するとパースが困難になる

この方式は要件をすべて満たしており、実用的なトレードオフを持つ。

---

### 選択肢3: プリフェッチ・プリマッピング方式

LLMに回答生成させる前に、使用予定のソースリストをあらかじめ確定する。

**動作原理:**
1. RAG検索で取得したドキュメント群に対し、先に番号を割り当てる: `source_3 → [1]`、`source_7 → [2]`
2. LLMへのプロンプトに「以下のソースを使って回答せよ」として番号付きで渡す
3. LLMは最初から `[1]`、`[2]` という形式で回答を生成する
4. 変換処理は不要

**プロンプト例:**
```
以下のソースを参照して回答してください:
[1]: source_3 の内容...
[2]: source_7 の内容...
[3]: source_1 の内容...

質問: ...
```

**利点:**
- ストリーム中に変換処理が不要。LLM出力をそのまま表示できる
- 番号の整合性は原理的に保証される
- 実装が最もシンプル

**欠点:**
- LLMが指示通りの番号フォーマットを厳密に守ることは保証されない
- LLMが実際に使わなかったソースの番号もソース一覧に含まれる場合がある
- 検索結果として渡したすべてのソースに番号を割り当てる必要があり、番号の密度が低い場合（[1]と[5]だけ使われるなど）、ユーザーが混乱する可能性がある

---

### 選択肢4: デルタ置換ストリーム方式

クライアント側で動的にテキストを書き換えることを前提とした設計。

**動作原理:**
1. サーバーは内部識別子をそのままクライアントへストリーム送信する
2. クライアントは識別子を初出時に番号に変換し、マッピングを保持する
3. ストリーム完了後、ソース一覧をまとめて送信する

**利点:**
- 変換ロジックをクライアントに委譲できる
- サーバー処理がシンプルになる

**欠点:**
- クライアントにRAGの内部識別子が露出する（セキュリティ・抽象化の観点から問題）
- クライアント実装が複雑になる
- 識別子が露出している間のUIが不自然になる

---

## 推奨設計: ファーストアピアランス方式の詳細実装

要件を最もバランス良く満たすのは**選択肢2（ファーストアピアランス方式）**である。以下に詳細設計を示す。

### コアコンポーネント

```
RAGパイプライン
  │
  ├── [検索層] Retriever → {source_3: doc, source_7: doc, ...}
  │
  ├── [生成層] LLM Streaming → token stream with internal refs
  │
  └── [変換層] CitationRewriter (ストリームプロセッサ)
                │
                ├── Citation Tracker (マッピングテーブル管理)
                ├── Token Buffer (部分マッチ対応)
                └── → 変換済みトークンストリーム → クライアント
```

### CitationRewriter の状態管理

```python
class CitationRewriter:
    def __init__(self):
        # 内部識別子 → 表示番号のマッピング
        self.mapping: dict[str, int] = {}
        # 次に割り当てる番号
        self.next_number: int = 1
        # 部分一致用バッファ（"[source_" のような途中状態を保持）
        self.buffer: str = ""

    def assign_or_get(self, internal_id: str) -> int:
        if internal_id not in self.mapping:
            self.mapping[internal_id] = self.next_number
            self.next_number += 1
        return self.mapping[internal_id]

    def process_token(self, token: str) -> str:
        """
        トークンを受け取り、引用識別子を番号に変換して返す。
        部分一致の場合はバッファに蓄積し、確定次第フラッシュする。
        """
        self.buffer += token
        # バッファ内の完全な引用パターンを検出・変換
        result, self.buffer = self._transform(self.buffer)
        return result
```

### パターン検出の考慮事項

LLMが生成する引用フォーマットは事前にプロンプトで指定する必要がある。例えば `[source_N]` のような形式をsystem promptで明示する。

**部分マッチ問題**: トークンは文字単位で到着することがある。`[source_3]` というパターンが `[sou`、`rce_`、`3]` のように分割して届く場合、途中のトークンをそのまま出力すると不完全な文字列が表示される。

この問題への対処:
1. バッファに蓄積し、引用パターンの開始 `[` を検出したら完全な閉じ括弧 `]` まで待機する
2. タイムアウト付きでバッファをフラッシュする（無限待機を防ぐ）
3. 引用パターンに見えない部分は即時フラッシュする

### ストリームイベントの設計

クライアントとの通信プロトコル:

```
# ストリーミング中のイベント
data: {"type": "token", "content": "この手法は"}
data: {"type": "token", "content": "[1]"}        ← 変換済み
data: {"type": "token", "content": "で提案され"}
data: {"type": "citation_appeared", "number": 1, "id": "source_3"}  ← メタイベント
data: {"type": "token", "content": "[2]"}
data: {"type": "citation_appeared", "number": 2, "id": "source_7"}

# ストリーム完了時
data: {"type": "done", "sources": [
    {"number": 1, "id": "source_3", "title": "...", "url": "..."},
    {"number": 2, "id": "source_7", "title": "...", "url": "..."}
]}
```

`citation_appeared` イベントをインラインで送信することで、クライアントはソース一覧をインクリメンタルに構築できる。ユーザーは引用番号が出現したタイミングでソース情報をすでに確認できる。

### ストリーム完了時の整合性保証

ストリーム完了時に `done` イベントとしてソース一覧を送信する際、`citation_tracker.mapping` を使って以下を保証する:

1. **網羅性**: テキスト中に出現したすべての引用番号がソース一覧に含まれる
2. **整合性**: 番号とソースのマッピングが正確である
3. **順序**: ソース一覧は番号の昇順（＝文章中の初出順）で整列する

```python
def finalize(self, source_store: dict) -> list[SourceEntry]:
    return [
        SourceEntry(
            number=num,
            content=source_store[internal_id]
        )
        for internal_id, num in sorted(
            self.mapping.items(), key=lambda x: x[1]
        )
    ]
```

## エッジケースと対処

### LLMが同じソースを複数回引用する場合

マッピングテーブルに既存エントリがあれば同じ番号を返す。これは設計上正しい動作である。

### LLMが引用フォーマットを守らない場合

プロンプトエンジニアリングで対処する。Few-shotの例示と明示的な指示を組み合わせる。それでも守らない場合のフォールバックとして、ソース一覧をストリーム完了後に「参考資料」として付記する方式も検討する。

### 非常に長いストリームでバッファが肥大化する場合

引用パターンの最大長（例: `[source_999]` = 12文字）を上限としてバッファサイズを制限する。上限を超えてもパターンが完成しない場合はバッファをフラッシュして通常テキストとして扱う。

### 並行ストリームが複数ある場合

`CitationRewriter` インスタンスはリクエストスコープで生成する。状態を共有してはならない。

## 設計の評価

| 要件 | 対応状況 |
|------|----------|
| ストリーミング中にリアルタイムで引用番号を表示する | 満たす（トークン到着時に即変換）|
| 一度表示した番号が後から変わらない | 満たす（ファーストアピアランス方式の特性）|
| ストリーム完了時にソース一覧と整合している | 満たす（`citation_tracker.mapping` を元に生成）|

## まとめ

ストリーミングRAGシステムにおける引用リナンバリングは、**ファーストアピアランス方式**によって要件を満たしながら実用的な実装が可能である。

核心となるトレードオフは「引用番号の意味論的順序（関連度順・重要度順）」vs「リアルタイム性」であり、ストリーミングを維持する限り前者を完全には達成できない。ほとんどのユースケースでは文章中の初出順で番号が振られることに大きな問題はなく、このトレードオフは受容可能である。

もし関連度順の番号割り当てが絶対要件であれば、ポストプロセッシング方式（選択肢1）しか手段はなく、その場合はストリーミング体験を諦めるか、「先にスケルトン応答を表示して後から引用を補完する」という複雑なUIパターンを検討する必要がある。
