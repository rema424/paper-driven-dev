# LLM に「論文を書け」と言うだけで出力特性が変わる——しかしそれだけでは不十分だった

> **実験条件**: Model: GPT-5.2 (via Codex) | N: 2 (CS1: citation rendering, CS2: session management) | Date: 2026-02 | Evaluator: 著者
> **補足**: 3条件比較（A/B/C）と B バリアント比較（B1/B2/B3）の定量データは [comparison-data.md](../../paper/comparison-data.md) に集約。

## はじめに

LLM に設計上の問題を相談するとき、あなたはどんなプロンプトを書いていますか？

「この問題の解決策を提案してください」——おそらく多くの人がこう聞くでしょう。そして LLM は、正しい答えを返してくれます。

でも私は偶然、もっと良い聞き方を見つけました。

**「この問題について学術論文を書いてください」**

たったこれだけで、LLM の出力特性が変わります——構造が整い、探索範囲が広がり、形式性が高まります。しかし、実験を重ねるうちに、**それだけでは不十分**だとわかりました。

本当に重要な情報——矛盾する要求の定義、テスト条件の導出、制約の誠実な開示——は、**テンプレート**がないと出てこなかったのです。

この発見を体系化したのが **Paper-Driven Development（論文駆動開発）** です。

## フック: 一言で変わる出力特性

RAG システムの設計問題——ストリーミング中に引用番号をリアルタイムで正しく表示する方法——を LLM に聞くとき、「解決策を提案して」と「学術論文を書いて」で出力がどう変わるか試しました。

| 観点 | A: 通常プロンプト (avg) | B: 論文形式 (avg) | C: テンプレート (avg) |
| --- | ---: | ---: | ---: |
| 出力行数 | 62 | 90 | 129 |
| 既存アプローチ分析 | 1.5 | 2.0 | 4.0 |
| 矛盾する要求 | 0 | 0 | 2.5 |
| テスト可能な性質 | 0 | 0 | 6.5 |
| 制約の開示 | 1.5 | 1.5 | 4.0 |

（GPT-5.2、2ケーススタディの平均。全データは [comparison-data.md](../../paper/comparison-data.md) を参照）

> **注意**: 条件 A（通常プロンプト）は最適化していません（CoT やペルソナプロンプティング等は未使用）。強化版プロンプトとの比較は将来課題です。

確かに、B（論文形式）は A（通常）より出力が増え、構造も整います。**しかし**、矛盾する要求の定義もテスト条件の導出も、B では 0 のまま。「一言変えるだけ」で形式的な改善は得られましたが、設計分析として重要な情報は引き出せませんでした。

## But: フレーミング効果の天井

「論文形式で書いて」の言い方を変えたらどうなるか？ 3つのバリエーションを試しました。

| 条件 | プロンプト | 既存アプローチ (avg) | 矛盾する要求 (avg) | テスト条件 (avg) |
| --- | --- | ---: | ---: | ---: |
| B1 | 「学術論文の形式で書いて」 | 2.0 | 0 | 0 |
| B2 | 「論文を書いて」 | 2.5 | 0 | 0 |
| B3 | 「学術論文を書いて」 | 3.5 | 0 | 0 |
| C (参考) | テンプレート付き | 4.0 | **2.5** | **6.5** |

B1→B3 の順に、探索幅は広がり、学術的な慣行（キーワード、参考文献、要件の形式化）も充実していきます。B3 は独自に「評価指標と実験計画」セクションまで生成しました。

でも、**矛盾する要求もテスト条件も、どのバリアントでも 0 のまま**でした。

プロンプトの言い方を工夫しても超えられない壁——これを **フレーミング効果の天井** と呼んでいます。

## 解: テンプレートによる情報の外在化

テンプレート（条件 C）を使ったときだけ、co-primary 指標（矛盾する要求、テスト条件、制約の開示）が出現しました。

なぜか？ テンプレートが LLM に新しい能力を与えているわけではありません。証拠として、**3条件とも同じ正しい結論に到達**しています。LLM は答えを知っていました。

テンプレートの役割は**情報の外在化**です。「§1.2 に矛盾する要求を書け」「§6 にテスト条件を書け」と指定することで、LLM が省略しがちな分析ステップの実行を促す。手術のチェックリストが医師の能力を上げるのではなく、省略を防ぐのと同じ原理です。

## テンプレート

体系化した結果、以下の7セクション構造が効果的だとわかりました。

```
§1. 問題定義
  §1.1 背景
  §1.2 矛盾する要求（対立するトレードオフ）
  §1.3 本文書の範囲
§2. 現状のアーキテクチャと制約
§3. 既存アプローチとその限界
§4. 問題の本質
§5. 提案手法
§6. 検証可能な性質
§7. 制約と今後の課題
```

特に重要なのは:

- **§1.2**: 矛盾する要求を2つ以上特定する。片方しかなければ、問題は自明であり、この手法は不要
- **§3**: 既存手法の「限界」を必ず書かせる。利点だけでは分析にならない
- **§6**: テスト条件を Given/When/Then 形式で定義させる。実装前にテスト設計が可能になる

## 実務での使い分け: Tier 1 / Tier 2

| Tier | やること | コスト | 期待される効果 |
| --- | --- | --- | --- |
| **Tier 1** | プロンプトを「解決策を提案して」→「論文を書いて」に変える | ゼロ | 探索幅と形式性の向上 |
| **Tier 2** | 重要な設計判断で §1–§7 テンプレートを使う | テンプレート準備 | 矛盾する要求・テスト条件・制約の外在化 |

日常的な設計問題には Tier 1 で十分です。アーキテクチャの選定や複数のトレードオフが絡む問題には Tier 2 を検討してください。

## なぜ「論文を書け」で出力特性が変わるのか

正直に言うと、因果関係は検証できていません。しかし3つの仮説があります。

### 仮説 1: 学習データ品質効果

学術論文は査読済みの高品質テキストです。LLM は膨大な論文データで訓練されており、「論文を書け」というプロンプトが、高品質な出力パターンを活性化している可能性があります。

### 仮説 2: 暗黙的 Chain-of-Thought

論文形式は「問題定義→既存手法分析→本質の特定→提案→検証」という思考順序を構造的に強制します。これが意図せず Chain-of-Thought プロンプティングとして機能しているのかもしれません。

### 仮説 3: ペルソナ効果

「論文を書け」は暗黙的に「あなたは研究者です」というペルソナを設定します。B バリアント実験では、B3（「学術論文を書いて」）が B1（「形式で書いて」）より学術的な出力を生成しており、ペルソナ効果の部分的な証拠はあります。ただし、ペルソナ効果だけでは co-primary 指標は引き出せませんでした。

## Claude Code プラグインとして公開しました

この手法を誰でも簡単に試せるよう、Claude Code のプラグインとして公開しています。

```shell
# インストール
/plugin marketplace add rema424/paper-driven-dev
/plugin install paper-driven-dev@rema424-paper-driven-dev

# 使う
/paper-driven-dev:article 認証システムのセッション管理方式の選定
```

GitHub リポジトリ: https://github.com/rema424/paper-driven-dev

## 限界の正直な告白

- **N=2**: 2ケーススタディ、各条件1回の実行。統計的結論には不十分
- **単一モデル（GPT-5.2）**: 他の LLM での再現性は未検証（o3 で類似パターンの予備的観察あり）
- **著者評価**: 指標のカウントは著者が実施。独立した第三者による盲検評価が必要
- **トートロジー懸念**: テンプレートが要求する内容と計測指標が近接している。「外在化」として再解釈しているが、テンプレート遵守を測っている側面がある
- **出力量の交絡**: テンプレート条件は出力が長い。指標の増加が分析深度の反映なのか、単に量の増加なのかは未分離
- **D 条件の欠落**: 「論文形式なしのチェックリスト」（テンプレートと同じ分析項目を論文形式なしで要求）は未テスト
- **因果関係未確定**: 3つの仮説はいずれも検証困難。「関連が観測された」以上の主張はできない

それでも、ゼロコストの Tier 1（プロンプト変更）で出力特性が変わるなら、試してみる価値はあると思います。重要な設計判断には Tier 2（テンプレート）を併用してください。

---

GitHub: https://github.com/rema424/paper-driven-dev

サンプル（Before/After 比較）: リポジトリの `docs/examples/` を参照
