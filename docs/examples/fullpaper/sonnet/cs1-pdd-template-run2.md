# CS1 条件C: PDD Template — RAG引用リナンバリング (Run 2)

> **Run**: CS1-C-Run2
> **Date**: 2026-02-22
> **Model**: Claude Sonnet 4.6
> **Context**: Fresh agent invocation

---

# RAGストリーミングにおける引用リナンバリング問題：一貫性保証アーキテクチャの設計と検証

## 概要

Retrieval-Augmented Generation（RAG）システムにおいて、LLMがストリーミング形式で回答を生成する際、内部識別子（`source_3`, `source_7` 等）をユーザー向けの連番引用（`[1]`, `[2]`, `[3]`）にリアルタイムで変換する問題を考察する。本稿では、この問題が持つ本質的なトレードオフを明確化し、「割り当て優先・確定モデル」に基づく設計を提案する。提案手法は、番号の不変性と完了時整合性を両立しつつ、ストリーミングの即時性を維持するものである。

---

## §1. 問題定義

### §1.1 背景

大規模言語モデル（LLM）を検索拡張生成（RAG: Retrieval-Augmented Generation）システムに統合する実装において、情報の出典を明示する引用機構は応答の信頼性確保に不可欠である。RAGシステムは一般に以下の処理フローを持つ：ユーザーのクエリに対してベクトル検索等により複数のドキュメントチャンクを取得し、それらを LLM のコンテキストに挿入した上で回答を生成させる。LLMへの入力においては、各チャンクに `source_1`, `source_3`, `source_7` のような内部識別子が付与されることが多い。これはシステム内部でのドキュメント管理上の都合（インデックス番号、ハッシュ値のエイリアス等）に基づくものであり、必ずしも連続的な整数ではない。

一方、エンドユーザーへの表示においては、論文の参考文献欄や Wikipedia の脚注のように、`[1]`, `[2]`, `[3]` という連続番号で引用が表示されることが慣習的であり、ユーザビリティ上も望ましい。この内部識別子とユーザー向け連番の間の変換（リナンバリング）は、バッチ処理（非ストリーミング）の文脈では自明な後処理として実装できる。回答テキスト全体が確定した後、使用された引用を出現順に列挙し、`[1]`, `[2]`, ... を割り当てればよい。

しかしLLMのストリーミング生成が標準化された現代の RAGシステムでは、事情が根本的に異なる。ストリームは回答を token 単位で逐次的に出力するため、回答の全体が確定する前にユーザーは引用番号を視認する。このリアルタイム性と最終整合性の間に本問題の本質的困難が存在する。

### §1.2 矛盾する要求（対立するトレードオフ）

本問題には構造的に解消が困難な複数のトレードオフが存在する。

**トレードオフ1：即時表示性 vs. 番号確定性**

ストリーミングにおけるユーザー体験の中心的価値は「回答が生成されていく様子をリアルタイムに追える」ことである。引用番号の表示を回答完了まで保留することは技術的には可能だが、テキスト本文に `[?]` や `[loading]` のようなプレースホルダーを表示し続けることになる。これはユーザーに認知的負荷を与え、回答の信頼性に対する不信感を生じさせる可能性がある。一方、即座に番号を表示するならば、その番号が後続のストリームチャンクで矛盾を引き起こさない保証が必要となる。この二者は方向性が逆であり、一方を強化すると他方が弱まる。

**トレードオフ2：番号の不変性 vs. 最適な番号順序**

引用番号の連番化において「出現順に番号を割り当てる」ことは、読者にとって最も自然な慣習に従ったものである。しかしストリーミング中に出現順で番号を確定させると、後から出現した引用に対して既に確定した番号の相対的な意味が変化する可能性がある（例：`source_7` が最初に `[1]` として確定した後、`source_3` が `[2]` として確定するが、本来なら出典の重要度や文書中の出現位置からは逆順の方が適切であった等）。番号の意味的最適性と変更不可性は両立しない。

**トレードオフ3：クライアントの単純性 vs. サーバーの処理複雑性**

リナンバリングの変換ロジックをサーバー側で完結させることでクライアントを単純化できる。しかしストリーミング中の変換をサーバーが担う場合、ストリームのバッファリング、引用検出のパーシング、番号割り当て状態の保持が必要となり、サーバーの処理複雑性とレイテンシが増大する。逆にクライアント側で変換を行うと、クライアントとサーバーの間の状態同期プロトコルが必要になる。いずれにせよ複雑性は完全には除去できず、システムのどこかに配置されるだけである。

**トレードオフ4：引用の完全性 vs. 引用の精度**

ストリーミング完了後のソース一覧には、LLMが実際に参照したソースを漏れなく含める必要がある（完全性）。同時に、回答本文中に引用として現れなかったソースをリストに含めることは余剰情報であり（精度の低下）、ユーザーを混乱させる。ストリーミング前に全引用候補を確定することは完全性を高めるが精度を犠牲にし、ストリーミング完了を待って引用を確定することは精度を高めるが完全性の保証が遅延する。

### §1.3 本文書の範囲

本稿は以下を対象とする：

- ストリーミング RAG において引用リナンバリングが生じる根本的な原因の分析
- 既存の実装アプローチの類型化とその限界の明示
- 問題の本質的構造の形式化
- 「割り当て優先・確定モデル」に基づく提案アーキテクチャの記述
- 検証可能な性質の Given/When/Then 形式による定義
- 残存する制約と今後の課題の整理

ただし特定のプログラミング言語や LLM プロバイダーの API への依存を排し、アーキテクチャレベルの設計として記述する。パフォーマンスのマイクロ最適化、セキュリティ要件、多言語対応等は本稿の範囲外とする。

---

## §2. 現状のアーキテクチャと制約

典型的なストリーミング RAG システムの処理フローは以下の通りである。

**検索フェーズ：** ユーザークエリをエンベディングに変換し、ベクトルストアに対して近傍検索を実行する。上位 K 件のドキュメントチャンクが取得される。各チャンクには内部識別子（`source_id`）が付与されており、これはしばしば非連続の整数またはハッシュ値である。

**プロンプト構築フェーズ：** 取得されたチャンクをシステムプロンプトに埋め込む。LLMに対しては「引用する際は `[source_3]` のような形式で参照せよ」という指示が与えられることが多い。

**生成・ストリーミングフェーズ：** LLM は token を逐次的に生成し、それがストリームとしてサーバーから送信される。HTTP Server-Sent Events（SSE）や WebSocket が一般的なプロトコルである。

**クライアント表示フェーズ：** クライアントは受信した token を順次レンダリングする。引用識別子が `[source_3]` のような形式であれば、それをユーザー向けの `[1]` に変換する何らかの機構が必要となる。

この標準的なフローにおける構造的制約を整理する：

- **前向きの知識の欠如：** ストリームの先頭では、後続でどの `source_id` が出現するかが不明である。LLM の生成はマルコフ的であり、サーバーは生成が完了するまで全体の引用セットを把握できない。
- **再送信のコスト：** 一旦クライアントに送信した token を「撤回」する標準的な HTTP プロトコルは存在しない。番号を変更するためには差分更新メッセージまたは全体の再送が必要となる。
- **引用形式の可変性：** LLM が `[source_3]` を確実に出力するという保証はなく、`source 3`, `(source_3)`, `^[source_3]` 等の形式的変異が生じうる。これはパーサーの信頼性を根本的に制限する。
- **チャンク境界の問題：** SSE のチャンクは token 境界と一致しないことがある。`[sour` と `ce_3]` が別チャンクで到着した場合、引用識別子の検出はチャンクをまたぐバッファリングを必要とする。

---

## §3. 既存アプローチとその限界

### §3.1 アプローチ1：完了後一括変換（Post-hoc Renumbering）

**手法：** LLM のストリーミングを内部バッファに蓄積し、ストリーム完了後に全テキストを走査して `source_id` の出現順に `[1]`, `[2]`, ... を割り当てる。変換済みテキストをクライアントに送信する。ユーザー向けには「生成中...」インジケーターのみが表示され、完了後に回答全体が一度に表示される。

**利点：**
- 実装が単純。全情報が揃った状態で変換できる。
- 番号の一貫性が保証される。
- 出現順の最適な番号割り当てが可能。

**限界：**
- ストリーミングの体験価値を完全に失う。ユーザーは長い待ち時間を経験する。
- LLM プロバイダーの API がストリーミングを前提とする場合、バッファリングのオーバーヘッドが発生する。
- Time-to-First-Token（TTFT）が最大化される。体験品質の観点から現代の RAG UI では受け入れがたい。

### §3.2 アプローチ2：クライアントサイド置換（Client-side Mapping）

**手法：** サーバーは LLM の生成をそのままストリーミングし（内部識別子を含む）、クライアントが `source_id` → `[N]` のマッピングを管理する。最初に `source_3` が出現した時点でクライアントは `[1]` を割り当て、次に異なる `source_id` が出現した時点で `[2]` を割り当てる。ストリーム完了後に確定したマッピングをソース一覧のレンダリングに使用する。

**利点：**
- ストリーミング体験を維持しつつリナンバリングが可能。
- サーバー側のロジックが単純。
- 出現順に番号が割り当てられる。

**限界：**
- 内部識別子（`source_3`）がユーザーに一瞬見える可能性がある（レンダリングのタイミング次第）。
- LLM が引用形式を変化させると、クライアントのパーサーが失敗する。
- クライアント実装が複雑化する（状態管理、正規表現パーシング）。
- `source_id` が機密情報（内部 DB のキー等）を含む場合、クライアントへの露出はセキュリティリスクとなる。

### §3.3 アプローチ3：事前番号付与（Pre-assigned Numbering）

**手法：** 検索フェーズで取得した K 件のチャンクに対し、事前に `[1]`〜`[K]` の番号を割り当て、LLM のプロンプトに番号付きで埋め込む。LLM は最初から `[1]`, `[3]` 等の形式で引用するよう指示される。サーバーは変換なしに LLM の出力をそのままストリームする。

**利点：**
- リナンバリング変換が不要。LLM が正しい番号を直接生成する。
- サーバーのストリーム処理が単純。
- `source_id` がクライアントに露出しない。

**限界：**
- 事前に割り当てた番号は検索結果の順序に依存するため、出現順とは一致しない。例えば `[3]` が回答で最初に引用されても、番号は `[3]` のままであり、ユーザーには `[1]` から始まらない不連続な番号が表示される。
- LLM は指示された番号を正確に守らないことがある（幻覚、フォーマット違反）。
- 引用されなかったソースが `[1]`〜`[K]` のリストに含まれる（精度の低下）。
- 取得チャンク数 K が変化する場合、プロンプトと番号スキームの管理が煩雑になる。

### §3.4 アプローチ4：二段階ストリーミング（Two-phase Streaming）

**手法：** 第1フェーズで LLM に引用なし（または内部識別子のみ）の回答を生成させ、完了後に第2フェーズで別の LLM 呼び出しにより引用番号を挿入した最終回答をストリームする。あるいは、第1フェーズ完了後に正規表現処理で識別子を置換し、第2フェーズでストリームする。

**利点：**
- 最終的な出力における番号の一貫性が保証される。
- 第2フェーズのストリームは変換済みであるため、番号の不変性を保つ。

**限界：**
- LLM 呼び出しが2回発生するため、コストとレイテンシが倍増する。
- 第1フェーズと第2フェーズの間にユーザーは待機を余儀なくされる（TTFT の問題は解消されない）。
- 第2フェーズの LLM が第1フェーズの出力を忠実に再現する保証がない（創造的な言い換えが生じる可能性）。

---

## §4. 問題の本質

上述の分析を踏まえ、本問題の本質的構造を以下のように形式化する。

引用リナンバリング問題とは、**単調増加する番号割り当て関数の定義域が実行時に逐次的に拡大する**という問題である。

より正確には：ストリームが進行するにつれ、使用引用集合 $S = \{s_1, s_2, \ldots, s_k\}$ が逐次的に確定していく（ここで $s_i$ は内部識別子）。番号割り当て関数 $f: S \rightarrow \mathbb{N}$ は全単射であり、かつユーザー向けには $f$ の像が $\{1, 2, \ldots, |S|\}$ であることが望まれる（連番性）。さらに $f$ は一度割り当てが確定した後に変更されてはならない（不変性）。

しかし $|S|$ がストリーム完了まで不明である以上、連番性と不変性を同時に実現する連続割り当て戦略は原理的に存在しない。これが本問題の本質的制約である。

この制約は以下のように証明できる：仮に $s_1$ が最初に出現した時点で $f(s_1) = 1$ と割り当てたとする（出現順割り当て）。その後 $s_2, s_3, \ldots$ が出現するたびに $f(s_i) = i$ が確定する。この戦略において不変性は満たされる。しかし連番性の定義を「最終的に割り当てられた番号の集合が $\{1, 2, \ldots, |S|\}$ に等しい」とするならば、出現順割り当ては連番性も満たす。

したがって問題の焦点は「連番性 vs. 不変性」のトレードオフではなく、**番号割り当てのタイミング**と**割り当て番号の意味的妥当性**のトレードオフである。出現順割り当ては意味的妥当性を「最初の出現順」に定義するならば最適であるが、「文書の重要度順」「アルファベット順」等の別の基準では最適でない場合がある。ただし意味的妥当性の定義がストリーム完了前に確定しない場合（文書重要度がストリーム完了後に判明する等）、出現順割り当てが唯一実用的な選択肢となる。

さらに重要な洞察として：本問題は**決定論的引用解析の不可能性**という副次的問題を内包している。LLM の出力における引用形式の揺らぎ（§2 で述べたもの）により、完全に信頼できる引用パーサーを構築することは原理的に困難である。このパーシングの不確実性が、リナンバリング機構の信頼性を根本的に制限する。

---

## §5. 提案手法

### §5.1 基本原理

本稿が提案する手法は「**割り当て優先・確定モデル（Assign-on-First-Encounter, Commit Model）**」と呼ぶ。基本原理は以下の三点である。

**原理1：出現時即時割り当て（Assign-on-First-Encounter）**
ストリーム処理中に未割り当ての `source_id` が初めて検出された時点で、次の番号を即座に割り当てる。一度割り当てられた番号は以後変更されない。これにより出現順連番と不変性が同時に実現される。

**原理2：バッファリング窓による引用検出（Windowed Buffering）**
チャンク境界をまたぐ引用識別子の問題に対応するため、固定長の「検出窓」バッファを維持する。ストリームチャンクを受信するたびにバッファに追記し、完全な引用識別子パターン（`[source_N]` 等）を検出した時点で番号割り当てを行い、変換済みテキストをクライアントに送出する。

**原理3：ストリーム完了時の整合性検証（Completion-time Reconciliation）**
ストリーム完了後に、割り当てられた番号マッピングとソース一覧を照合する。LLM が引用した `source_id` のみをソース一覧に含め、番号の整合性を最終確認する。不整合があればメタデータのみを修正し（テキスト本体は変更しない）、ソース一覧を確定送信する。

### §5.2 実装アーキテクチャ

提案アーキテクチャは以下のコンポーネントから構成される。

**コンポーネント1：CitationMapper（引用マッパー）**

引用マッパーは `source_id` → 連番のマッピング状態を管理するステートフルなコンポーネントである。

```
CitationMapper:
  state:
    mapping: Map<source_id, number>   // 割り当て済みマッピング
    next_number: number               // 次に割り当てる番号（初期値: 1）

  method assign(source_id):
    if source_id not in mapping:
      mapping[source_id] = next_number
      next_number += 1
    return mapping[source_id]

  method get_mapping():
    return mapping (read-only)
```

このコンポーネントはスレッドセーフである必要があるが、単一ストリームの処理においては逐次的アクセスのみが生じるため、ロック機構は不要である。

**コンポーネント2：StreamParser（ストリームパーサー）**

ストリームパーサーは受信したチャンクをバッファリングし、引用識別子の検出と変換を担う。

```
StreamParser:
  state:
    buffer: string                    // 検出窓バッファ
    PATTERN: RegExp                   // 引用識別子パターン
    mapper: CitationMapper

  method process(chunk):
    buffer += chunk
    output = ""
    while buffer contains PATTERN:
      prefix = buffer content before first PATTERN match
      match = first PATTERN match (source_id extracted)
      number = mapper.assign(match.source_id)
      output += prefix + "[" + number + "]"
      buffer = buffer content after match
    // バッファに残ったテキストのうち、パターンの前置詞でないことが
    // 確定している部分を出力
    safe_prefix = buffer.get_safe_prefix(PATTERN)
    output += safe_prefix
    buffer = buffer without safe_prefix
    return output

  method flush():
    // ストリーム完了時：バッファ残余をそのまま出力
    return buffer
```

ここで `get_safe_prefix` は、バッファの先頭から、いかなる引用識別子の前置詞にもなりえない部分を返す関数である。例えばパターンが `\[source_\d+\]` であれば、バッファ末尾が `[sou` で終わっている場合、この部分は引用識別子の前置詞である可能性があるため安全な前置詞には含めない。

**コンポーネント3：SourceReconciler（ソース照合器）**

ストリーム完了後に動作するコンポーネントで、CitationMapper の最終状態に基づいてソース一覧を構築する。

```
SourceReconciler:
  method reconcile(mapper, source_store):
    final_mapping = mapper.get_mapping()
    sources = []
    for source_id, number in final_mapping sorted by number:
      doc = source_store.fetch(source_id)
      sources.append({
        "number": number,
        "source_id": source_id,
        "title": doc.title,
        "url": doc.url,
        "excerpt": doc.excerpt
      })
    return sources
```

**データフロー図（テキスト表現）：**

```
[LLM Stream] → [StreamParser] → [Transformed Stream] → [Client]
                    ↕
              [CitationMapper]
                    ↓
[Stream Complete] → [SourceReconciler] → [Source List] → [Client]
```

**SSEプロトコル設計：**

クライアントとのプロトコルは以下のイベントタイプを定義する：

- `event: token` — 変換済みテキストチャンク（引用番号は確定済み）
- `event: done` — ストリーム完了通知
- `event: sources` — ソース一覧（`done` の後に送信）

```
event: token
data: {"text": "詳細については [1] を参照してください。"}

event: token
data: {"text": "また、[2] によれば..."}

event: done
data: {}

event: sources
data: {"sources": [{"number": 1, "title": "...", "url": "..."}, ...]}
```

この設計において、クライアントは `token` イベントを受信するたびにテキストを追記描画するだけでよく、引用番号の変換ロジックをクライアントに持つ必要がない。

---

## §6. 検証可能な性質

提案手法が満たすべき性質を Given/When/Then 形式で定義する。

---

**性質1：番号の不変性（Immutability of Citation Numbers）**

```
Given: ストリーミングが進行中であり、source_id "source_3" に番号 [1] が割り当てられている
When:  その後のストリームに "source_7" が初めて出現し、[2] が割り当てられた
Then:  "source_3" に割り当てられた番号は依然として [1] のままであり、
       クライアントが以前に受信した "[1]" という文字列は変更されない
```

---

**性質2：出現順連番性（Sequential Numbering by Appearance Order）**

```
Given: 空の CitationMapper（割り当てなし）
When:  ストリームに "source_7", "source_3", "source_1" の順で引用が出現した
Then:  割り当ては f("source_7") = 1, f("source_3") = 2, f("source_1") = 3 となる
       クライアントへの出力は [1], [2], [3] の順で表示される
```

---

**性質3：重複出現の冪等性（Idempotency for Repeated Citations）**

```
Given: "source_3" に番号 [1] が割り当て済みである
When:  ストリームに再度 "source_3" が出現した
Then:  番号 [1] が再度使用され、新しい番号は割り当てられない
       CitationMapper の next_number は変化しない
```

---

**性質4：ソース一覧との整合性（Consistency with Source List）**

```
Given: ストリームが完了し、CitationMapper には {source_3: 1, source_7: 2} が記録されている
When:  SourceReconciler が source_store に対して照合を行う
Then:  返却されるソース一覧は番号1に source_3 のメタデータ、
       番号2に source_7 のメタデータを含む
       回答本文中に出現しなかった source_id はソース一覧に含まれない
```

---

**性質5：チャンク境界をまたぐ引用の正確な検出（Cross-boundary Citation Detection）**

```
Given: StreamParser のバッファが "[sour" を保持している
When:  次のチャンク "ce_3]" が到着する
Then:  バッファは "[source_3]" として完全な識別子を認識し、
       mapper.assign("source_3") が呼ばれ、変換済みテキスト "[N]" が出力される
       バッファは空になる（または次の識別子処理のために残余が保持される）
```

---

**性質6：未出現ソースの除外（Exclusion of Unreferenced Sources）**

```
Given: RAG システムが 5件のチャンク (source_1 〜 source_5) を検索結果として取得した
When:  LLM が生成した回答が source_2 と source_4 のみを引用してストリームが完了した
Then:  ソース一覧には source_2（番号1または出現順の番号）と source_4（番号2等）のみが含まれる
       source_1, source_3, source_5 はソース一覧に含まれない
```

---

**性質7：識別子の非露出性（Non-exposure of Internal Identifiers）**

```
Given: クライアントとのSSE通信が確立している
When:  ストリーミングが進行し、source_id "source_3" が変換される
Then:  クライアントが受信する `event: token` データには "source_3" という文字列は含まれない
       クライアントは "[1]" のような連番形式のみを受信する
```

---

## §7. 制約と今後の課題

**制約1：LLM 出力形式の依存性**

提案手法の StreamParser は引用識別子のパターン（正規表現）に依存する。LLM が `[source_3]` の代わりに `source 3` や `(ref: source_3)` のような形式を出力した場合、検出が失敗する。この問題への根本的対処には、LLM への Few-shot プロンプティングによる形式の強制や、構造化出力（Structured Output / Function Calling）の活用が必要である。ただし構造化出力はストリーミングとの統合が一部の LLM プロバイダーで未対応または制限されており、普遍的な解決策ではない。

**制約2：引用の連続性に関する意味的限界**

出現順割り当ては実装上最も単純だが、ユーザーが「番号順にソース一覧を参照する」という慣習的行動において、番号が文書の重要度や信頼性を暗示しないことへの理解を前提とする。システムが意味的に重要なソースを優先的に低い番号で表示したい場合（例：信頼スコア順）、出現順割り当ては適切でない。この場合は §3.3 の事前番号付与アプローチが候補となるが、連番性の問題（使用されないソースへの番号割り当て）を別途解決する必要がある。

**制約3：バッファリングによるレイテンシの増大**

StreamParser の検出窓バッファは、潜在的な引用識別子の前置詞部分を送信保留にするため、数百ミリ秒〜数秒のレイテンシを生じさせる可能性がある。引用識別子が回答の末尾に集中するような生成パターン（「...の通りです。[source_3][source_7]」）では、回答テキストの大半が即時送信されるが、引用部分でバッファが蓄積する。パターンの長さと遅延のバランスを調整する設計パラメータ（バッファ最大長のタイムアウト等）が必要である。

**制約4：引用解析の正確性とフォールバック**

パーシングが失敗した引用識別子（形式の揺らぎ等）は、変換されないまま内部識別子としてクライアントに露出する可能性がある（性質7の違反）。このフォールバックシナリオに対し、内部識別子を汎用的な `[ref]` プレースホルダーで置換するか、あるいはそのまま出力するかの選択が必要であり、システムの目的（セキュリティ vs. 透明性）に依存する。

**今後の課題1：LLM 生成の引用集中パターンの実証分析**

実際の LLM（GPT-4, Claude, Gemini 等）がどのような位置（文頭、文末、段落末尾等）に引用を配置するかを実証的に分析することで、StreamParser の検出窓の最適長を決定できる。またプロンプト設計（「各文の直後に引用を配置せよ」等）によって引用位置を制御できるかの検証も有益である。

**今後の課題2：Structured Output との統合**

LLM プロバイダーが JSON Schema に基づく Structured Output とストリーミングを同時サポートする機能が整備されつつある（OpenAI の `stream_options`, Anthropic の streaming tool use 等）。引用をテキスト埋め込みではなく、構造化フィールドとして独立させることで、パーシングの信頼性問題を根本から回避できる可能性がある。例えば回答を `{"text": "詳細は参考文献を参照してください", "citations": [{"position": 15, "source_id": "source_3"}]}` のような形式で出力させ、クライアントが後処理で番号を埋め込む設計が考えられる。これはバッファリングなしに §1.2 の複数のトレードオフを緩和できる可能性があり、重要な研究方向である。

**今後の課題3：多並行ストリームにおける CitationMapper の共有**

同一ユーザーの複数の質問が並行してストリーミングされる場合（チャットインターフェースにおけるマルチターン等）、各ストリームが独立した CitationMapper を持つべきか、会話を通じて共有するかという設計判断が生じる。同一ソースが複数の回答で引用される場合、番号の一貫性をセッション全体で保つかどうかはユーザー体験に影響する。この問題は本稿の範囲を超えるが、実装において重要な考慮事項である。

---

## 参考文献

本稿は特定の論文や実装への直接的な引用を含まないが、以下の関連領域の先行研究が背景として参照される：

- Lewis, P. et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. *NeurIPS 2020*.
- Shi, F. et al. (2023). REPLUG: Retrieval-Augmented Language Model Pre-Training. *arXiv:2301.12652*.
- 引用生成の評価フレームワークとしての ALCE (Gao et al., 2023)。

引用リナンバリング問題は RAG システムの実装論において比較的新しい課題であり、学術的な体系化はいまだ発展途中にある。本稿がその形式化の一助となることを期待する。
