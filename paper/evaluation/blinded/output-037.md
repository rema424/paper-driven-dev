# Output #037

1. **問題の背景と文脈**
- RAGでは検索結果（例: `source_3`, `source_7`）を根拠として、LLMが回答文を**ストリーミング**（逐次出力）します。
- ユーザー向けには内部IDではなく、本文中に読みやすい **`[1] [2] [3]`** のような連番引用を出し、最後に「`[1] = source_7 …`」のようなソース一覧を提示したい状況です。
- しかしストリーミング中は「最終的にどのソースが何回・どの順で参照されるか」が未確定で、**事後に付番し直す**と「すでに表示した番号が変わる」問題が起きます。

2. **対立する要求やトレードオフ（2つ以上）**
- **低遅延ストリーミング** vs **確定後の最適な整形**：全文確定を待てば付番は簡単ですが、リアルタイム表示が遅れます。
- **番号の不変性（後から変えない）** vs **後処理による修正（削除・統合・並べ替え）**：不変にすると後で"より良い"番号体系へ作り直せません。
- **引用粒度（チャンク単位の精密さ）** vs **可読性（番号の増えすぎ回避）**：チャンクごとに番号を振ると正確ですが、`[12][13][14]` のように読みにくくなりがちです。

3. **分析の対象範囲**
- 1回の回答ストリーム（1メッセージ）内での、**引用番号のオンライン（逐次）付与・表示・確定**。
- サーバ（ストリーム中継/整形）とクライアント（UI表示）の責務分割、引用データ構造、エラー時の扱い。
- 検索アルゴリズム自体の精度、再ランキング、要約品質などは主対象外（ただし"ソースIDは事前に確定している"前提は利用）。

4. **現状のアーキテクチャと制約**
- 典型構成：`Retriever -> 検索結果(内部ID付き) -> Prompt -> LLM(stream) -> クライアント表示`
- 制約:
  - ストリーミングは基本的に**追記のみ**で、既に表示した本文を後から安全に書き換えにくい（UIが差分更新できても、ユーザー視点では"変わった"になる）。
  - LLMが内部IDを本文に混ぜると、**パースが曖昧**（通常文として出てくる可能性）になりやすい。
  - 最後に出す「ソース一覧」は、本文で実際に参照されたものと**完全一致**している必要がある。

5. **既存の解決アプローチとその限界**
- 5.1 アプローチ1: **事後付番（全文確定後に置換）**
  - 手法: 出力完了後に本文を走査し、出現順に `[1]` を振って置換し、一覧を生成。
  - 利点: 実装が単純、番号が最終的に最適化しやすい。
  - 限界: ストリーミング中に番号を出せない／出しても後から変わり得る。
- 5.2 アプローチ2: **検索結果に先に固定番号を割り当て（retrieval順など）**
  - 手法: `source_1..N` に対し最初から `[1..N]` を固定し、LLMにはその番号を使わせる。
  - 利点: ストリーミング中も番号が不変、処理が軽い。
  - 限界: 実際に引用されないソースが混ざると番号が飛ぶ／"本文の初出順"と一致しない。
- 5.3 アプローチ3: **LLM自身に `[n]` を管理させる**
  - 手法: 「初出は[1]、次は[2]…」をプロンプトで指示。
  - 利点: 中継の実装が不要。
  - 限界: 重複・欠番・誤対応が起きやすく、要件（不変・整合）を強く保証できない。
- 5.4 アプローチ4: **2パス生成（先に"引用計画"→次に本文をストリーム）**
  - 手法: 1回目に引用IDの出現順だけ確定、2回目に本文をストリーム。
  - 利点: 番号確定後にストリームでき、整合性が高い。
  - 限界: 追加レイテンシ/コスト。2回目で計画とズレると破綻。
- 5.5 アプローチ5: **構造化"引用イベント"方式（本文と引用を別チャネルで流す）**
  - 手法: LLMは本文に埋め込まず、引用をイベント/ツール出力として送る（またはサーバが検出してイベント化）。
  - 利点: パースが堅牢、UIがリアルタイムに一覧更新しやすい。
  - 限界: 実装がやや重い（プロトコル設計・クライアント対応が必要）。

6. **問題の本質的な困難**
- 引用番号は「**本文全体の"初出順"**」という**グローバル性**を持つ一方、ストリーミングは**局所的・逐次的**で、未来の出現を見られません。
- さらに「一度表示した番号は変えない」という制約により、後処理での再付番（最も簡単な整合手段）が封じられます。
- したがって、必要なのは「未来を見ずに決めても破綻しない」**オンライン付番規則**と、それを強制する**生成/表示の分離**です。

7. **解決策**
7.1 **基本原理**
- **内部ID（sourceキー）と表示番号（[n]）を分離**し、番号はLLMではなく**サーバ側の決定的ロジック**で割り当てる。
- 付番規則は「**初めて参照されたsourceに次の番号を割り当てる**（first-seen）」のオンラインアルゴリズムに固定する。
- 本文ストリーム中に"確定した番号だけ"を出す（途中の仮番号・後置換をしない）。

7.2 **実装方針（推奨: ストリーム中継でのオンライン置換 + 末尾で一覧確定）**
- **(A) 引用マーカーを機械可読にする**
  - LLMには本文中で引用する際、必ず例のようなマーカーを出させます：`<<cite:source_7>>`（複数なら `<<cite:source_3,source_7>>`）
  - 逆に、LLMが `[1]` のような番号を直接出すことは禁止（番号はサーバが責任を持つ）。
- **(B) サーバに"引用番号レジストリ"を持たせる**
  - 状態: `map[source_key] -> n` と `ordered_sources = [(n, source_key, meta...)]`
  - マーカー検出時:
    - 既出なら同じ `n` を使う
    - 未出なら `n = next_id++` を割当てて `ordered_sources` に追加
  - 本文への出力は `<<cite:source_7>>` を **即座に `[n]` に置換**してストリーム送信（この時点で番号は確定し、以後変わりません）。
- **(C) ストリーミング中の"部分マーカー"対策**
  - `<<cite:` から `>>` までを検出できるまで、その区間は**バッファして表示しない**（誤って生のマーカーが見えると後で変わってしまうため）。
- **(D) ストリーム完了時のソース一覧生成**
  - LLMに一覧を生成させず、サーバが `ordered_sources` から確定一覧を作る。
  - UIは「本文とは別枠（サイドパネル/フッタ）」に `[n] タイトル/URL/抜粋` を表示する（またはサーバが本文末尾に追記する）。
- **(E) 粒度の正規化（任意だが実務上重要）**
  - `source_7` が"チャンクID"なら、同一ドキュメント配下のチャンクを同一番号にまとめる等、`source_key` を **doc-level key** に正規化して番号爆発を防ぐ。

8. **検証条件（Given/When/Then）**
- ケース1（初出の付番）
  - Given: `registry` が空
  - When: ストリーム中に `<<cite:source_7>>` を受信
  - Then: 本文には即時に `[1]` が出力され、一覧には `[1] -> source_7` が追加される
- ケース2（再引用の安定性）
  - Given: すでに `source_7 -> 1` が割り当て済み
  - When: 後続で `<<cite:source_7>>` を受信
  - Then: 出力は常に `[1]` で、新しい番号は発行されない
- ケース3（初出順の保証）
  - Given: まだ `source_3` と `source_7` は未登録
  - When: 出現順が `<<cite:source_7>>` → `<<cite:source_3>>` の順で到来
  - Then: 本文は `[1]` → `[2]`、一覧も `[1]=source_7, [2]=source_3` の順になる
- ケース4（ストリーム分割されたマーカー）
  - Given: あるチャンクで `"<<cite:so"`、次チャンクで `"urce_7>>"` が届く
  - When: 2つを連結してマーカーが完成する
  - Then: ユーザーに生マーカーは見えず、完成時点で一度だけ `[n]` が表示される
- ケース5（未知IDの混入）
  - Given: `source_999` は検索結果に存在しない
  - When: `<<cite:source_999>>` を受信
  - Then: 本文はポリシーに従い（例: 引用を抑止/`[?]` 表示/エラー）し、一覧も同ポリシーで整合する（"存在しないのに一覧に載る"を防ぐ）

9. **制約、限界、今後の課題**
- LLMがマーカー規約を破ると崩れるため、**プロンプト強化・出力検証（ガード）**が必要です。
- "一度出した番号を変えない"設計上、後から「不要引用を消す」「引用を統合して詰め直す」は原則できません（やるなら"全文再生成/再描画"が必要）。
- doc-level正規化を入れる場合、どの粒度を同一視するか（URL一致、同一文書ID、版など）を要件化する必要があります。
- クライアントが"本文末尾に参考文献を出したい"場合、サーバ追記方式が適しますが、UI/ログ上は「モデル出力」と「システム追記」を区別できる設計が望ましいです。
